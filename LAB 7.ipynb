{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c51460",
   "metadata": {},
   "source": [
    "## Word Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc9be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result \n",
      " [[1 1 0 1 0 1 1 1 1]\n",
      " [1 1 0 2 1 1 1 1 0]\n",
      " [0 0 1 1 0 1 0 1 2]]\n",
      "['affordable', 'and', 'delicious', 'is', 'not', 'pasta', 'tasty', 'this', 'very']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "all_s = [\"This pasta is very tasty and affordable.\",\"This pasta is not tasty and is affordable.\",\"This pasta is very very delicious\"]\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(all_s)\n",
    "ans = x.toarray()\n",
    "print(f\"Result \\n {ans}\")\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac567481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names \n",
      "['affordable', 'and', 'delicious', 'is', 'not', 'pasta', 'tasty', 'this', 'very']\n",
      "Final result \n",
      "    affordable       and  delicious        is       not     pasta     tasty  \\\n",
      "0    0.414896  0.414896   0.000000  0.322204  0.000000  0.322204  0.414896   \n",
      "1    0.346117  0.346117   0.000000  0.537582  0.455102  0.268791  0.346117   \n",
      "2    0.000000  0.000000   0.478909  0.282851  0.000000  0.282851  0.000000   \n",
      "\n",
      "       this      very  \n",
      "0  0.322204  0.414896  \n",
      "1  0.268791  0.000000  \n",
      "2  0.282851  0.728445  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "all_s = [\"This pasta is very tasty and affordable.\",\"This pasta is not tasty and is affordable.\",\"This pasta is very very delicious\"]\n",
    "cv = TfidfVectorizer()\n",
    "vectors = cv.fit_transform(all_s)\n",
    "feature_names = cv.get_feature_names()\n",
    "print(f\"feature names \\n{feature_names}\")\n",
    "\n",
    "matrix = vectors.todense()\n",
    "denselist = matrix.tolist()\n",
    "df = pd.DataFrame(denselist,columns = feature_names)\n",
    "print(f\"Final result \\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61ddb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.28.5\n",
      "    Uninstalling Cython-0.28.5:\n",
      "      Successfully uninstalled Cython-0.28.5\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4416cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.9979764\n",
      "Cosine similarity between 'alice' and 'machines' - CBOW :  0.95462716\n",
      "Cosine similarity between 'alice' and 'wonderland' - Skip Gram :  0.83389074\n",
      "Cosine similarity between 'alice' and 'machines' - Skip Gram :  0.8580576\n"
     ]
    }
   ],
   "source": [
    "# Python program to generate word vectors using Word2Vec\n",
    "  \n",
    "# importing all necessary modules\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "  \n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "  \n",
    "#  Reads ‘alice.txt’ file\n",
    "sample = open(\"text.txt\", encoding=\"utf8\")\n",
    "s = sample.read()\n",
    "  \n",
    "# Replaces escape character with space\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "  \n",
    "data = []\n",
    "  \n",
    "# iterate through each sentence in the file\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "      \n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "  \n",
    "    data.append(temp)\n",
    "  \n",
    "# Create CBOW model\n",
    "# CBOW tries to predict a word on the basis of its neighbors,\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1, window = 5)\n",
    "  \n",
    "# Print results\n",
    "print(\"Cosine similarity between 'alice' \" + \n",
    "               \"and 'wonderland' - CBOW : \",\n",
    "    model1.wv.similarity('alice', 'wonderland'))\n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "                 \"and 'machines' - CBOW : \",\n",
    "      model1.wv.similarity('alice', 'machines'))\n",
    "  \n",
    "# Create Skip Gram model\n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1,\n",
    "                                             window = 5, sg = 1)\n",
    "  \n",
    "# Print results\n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "          \"and 'wonderland' - Skip Gram : \",\n",
    "    model2.wv.similarity('alice', 'wonderland'))\n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "            \"and 'machines' - Skip Gram : \",\n",
    "      model2.wv.similarity('alice', 'machines'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfd900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
